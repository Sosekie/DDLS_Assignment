关于健康的时序信息往往与个人隐私高度相关。虽然用户对自己的个人时序信息很在意，不希望别人知道，但是他们往往想得到更多关于自己状况的信息。比如一个用户的手表只能记录心跳信息，但他还想知道自己的呼吸频率等等信息。这就需要有一种方法能在用户完全无法提供一些数据的情况下生成出可信的信息作为参考。
联邦学习能在不泄露用户个人信息的情况下完成训练。但传统的联邦学习对每个client上feature的维度有严格的要求，无法很好处理未知feature完全缺失的情况。
本文探讨了如何在一些clients完全缺失一些features的情况下对这些不存在的feature进行生成，探讨了FedAvg和Multi-FedAvg的生成能力和可信度，并提出了两种新的针对完全缺失情形的联邦学习方法：WeightedFedAvg和DynamicFedAvg.
实验证明我们提出的方法优于只使用FedAvg的方法。

联邦学习范式允许在不接触用户原始数据的情况下完成模型的训练，为用户提供保障个人隐私的服务。这对于有关个人健康的心跳等相当隐私的数据尤其重要。但是，除了保护个人隐私，用户可能还想要更多关于自己身体状况的“信息”，比如一个用户的手表只能记录心跳数据，但他还想知道自己的呼吸速率等信息(尽管他无法记录这些信息）。
在中心化学习范式中，我们可以使用如MAE等方法对训练数据进行部分掩码，再去生成对应的预测，来增强模型处理缺失数据的能力。但在联邦学习中，用户不希望自己的数据被上传到服务器上进行训练，也不希望别人知道自己具体有哪些信息。他们可能愿意共享的信息只有“特征总数”。那我们如何针对这种情况进行优化呢？
一种简单的情况是每个client只和具有相同特征的client进行aggregate，但是之前说过：用户不愿意提供自己有哪些信息。而且这样也不能为用户生成他想要的其他信息。另一种方法是直接固定模型的输入输出维度，用户输入自己有的特征，而其它特征置为0，并且只使用自己有的feature计算loss，进行模型的训练。之后，所有的client上的model都在server上进行aggregate。然而这样做会严重拉低具有更多feature的client的准确率。
Contributions. 针对以上问题，本文提出了WeightedFedAvg以及DynamicFedAvg，两种比起FedAvg可以在完全缺失某些数据的情况下进行更准确生成和预测时序信息的联邦学习模型。主要思想是比起FedAvg直接对所有client上的所有weights进行求和平均，我们充分考虑到每个client上feature的丰富程度，来对如何aggregate weight进行衡量，具体如下：
1. WeightedFedAvg利用每个client有的feature数量和数据集大小计算权重，来限制在较少feature的dataset上训练的model对其它在较多feature的dataset上训练的、表现更好的model的影响；
2. DynamicFedAvg也是利用每个client有的feature数量和数据集大小来衡量如何aggregate weight，但采用动态变化的方式：刚开始训练的时候，只有拥有全部feature的client的weight会被考虑aggregate；过了一段时间后，拥有90%以上feature的client会被考虑aggregate，以此类推。
实验证明，我们提出的方法比起只使用FedAvg在各个数据集上取得了普遍更好的结果。
